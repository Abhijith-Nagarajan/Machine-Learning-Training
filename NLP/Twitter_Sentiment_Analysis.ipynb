{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "015a1d24",
   "metadata": {},
   "source": [
    "### Implementing Sentiment Analysis for the Machine Hack Hackathon using the Tf-IDF model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9181e8f1",
   "metadata": {},
   "source": [
    "#### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d3cde7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3181f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c78617b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.distributed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b3791ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f200966",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "365e1cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e420538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44100 entries, 0 to 44099\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ID         44100 non-null  int64 \n",
      " 1   author     44100 non-null  object\n",
      " 2   Review     44100 non-null  object\n",
      " 3   Sentiment  44100 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "twitter_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77631534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>author</th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39467</td>\n",
       "      <td>rayinstirling</td>\n",
       "      <td>Today I'm working on my &amp;quot;Quirky Q&amp;quot; c...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30154</td>\n",
       "      <td>DirtyRose17</td>\n",
       "      <td>@ShannonElizab dont ya know? people love the h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16767</td>\n",
       "      <td>yoliemichelle</td>\n",
       "      <td>ughhh rejected from the 09 mediation program. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9334</td>\n",
       "      <td>jayamelwani</td>\n",
       "      <td>@petewentz im so jealous. i want an octo drive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61178</td>\n",
       "      <td>aliisanoun</td>\n",
       "      <td>I remember all the hype around this movie when...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>54688</td>\n",
       "      <td>empressjazzy1</td>\n",
       "      <td>I liked this quite a bit but I have friends th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34838</td>\n",
       "      <td>lorrief</td>\n",
       "      <td>loving that spring definitely seems to be here...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28520</td>\n",
       "      <td>GE0RGIE</td>\n",
       "      <td>@jeg007jeg yay  coutch:couch</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31974</td>\n",
       "      <td>BrandonCarlson</td>\n",
       "      <td>Working on the store's Facebook group, getting...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14323</td>\n",
       "      <td>allshookup</td>\n",
       "      <td>@falselove OH THAT'S GOOD! My top 4 are: The H...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID          author                                             Review  \\\n",
       "0  39467   rayinstirling  Today I'm working on my &quot;Quirky Q&quot; c...   \n",
       "1  30154     DirtyRose17  @ShannonElizab dont ya know? people love the h...   \n",
       "2  16767   yoliemichelle  ughhh rejected from the 09 mediation program. ...   \n",
       "3   9334     jayamelwani     @petewentz im so jealous. i want an octo drive   \n",
       "4  61178      aliisanoun  I remember all the hype around this movie when...   \n",
       "5  54688   empressjazzy1  I liked this quite a bit but I have friends th...   \n",
       "6  34838         lorrief  loving that spring definitely seems to be here...   \n",
       "7  28520         GE0RGIE                       @jeg007jeg yay  coutch:couch   \n",
       "8  31974  BrandonCarlson  Working on the store's Facebook group, getting...   \n",
       "9  14323      allshookup  @falselove OH THAT'S GOOD! My top 4 are: The H...   \n",
       "\n",
       "   Sentiment  \n",
       "0          2  \n",
       "1          1  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "5          2  \n",
       "6          2  \n",
       "7          2  \n",
       "8          2  \n",
       "9          0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e0080",
   "metadata": {},
   "source": [
    "It can be seen that data cleaning is required. This is because:\n",
    "- Some reviews have the user's info seen as: @username\n",
    "- There are words which do not necessarily contribute to the sentiment expressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "186323e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "743b7600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6211f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a447e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_series = twitter_df[\"Review\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebc0c67",
   "metadata": {},
   "source": [
    "#### Starting with the text cleaning and following these steps:\n",
    "1) Converting all data to lower case<br>\n",
    "2) Removing punctuations<br>\n",
    "3) Removing HTML tags<br>\n",
    "4) Removing stopwords<br>\n",
    "5) Performing lemmatization<br>\n",
    "> a) Using Spacy lemmatizer<br>\n",
    "> b) Using textblob lemmatizer\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58c57d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_series = review_series.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73324363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "757e28b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30826636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(review):\n",
    "    return review.translate(str.maketrans('','',punctuations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7e0f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_series = review_series.apply(lambda review: remove_punctuations(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6ca454f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        today im working on my quotquirky qquot cue or...\n",
       "1        shannonelizab dont ya know people love the hum...\n",
       "2        ughhh rejected from the 09 mediation program s...\n",
       "3             petewentz im so jealous i want an octo drive\n",
       "4        i remember all the hype around this movie when...\n",
       "                               ...                        \n",
       "44095    the mother is a weird lowbudget movie touching...\n",
       "44096    it started off weird the middle was weird and ...\n",
       "44097    i was amazed at the quick arrival of the two o...\n",
       "44098    attractive marjoriefarrah fawcettlives in fear...\n",
       "44099    refugee me gets quotyour video will start in 1...\n",
       "Name: Review, Length: 44100, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e640d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(review):\n",
    "    review = re.sub('<.*?>','',review)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "314f0214",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_series = review_series.apply(lambda review:remove_html_tags(review))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854f1ab6",
   "metadata": {},
   "source": [
    "#### Instead of performing steps 4 and 5 separately, they will be combined in such a way that words not part of the stopwords will be lemmatized and retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0eb7b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6f6d6c",
   "metadata": {},
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bf69152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob,Word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c7b9b5",
   "metadata": {},
   "source": [
    "#### Performing lemmatization with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc3378b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "582302b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_review = dd.from_pandas(review_series,npartitions=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "147dbcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_and_lemmatize_spacy(review):\n",
    "    doc = nlp(review)\n",
    "    return \" \".join([token.lemma_ for token in doc if token.is_stop == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32db32ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py:3545: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('Review', 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n"
     ]
    }
   ],
   "source": [
    "dask_review = dask_review.apply(lambda review: remove_stopwords_and_lemmatize_spacy(review)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75fc65bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.dataframe.core.Series"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dask_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a382f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_review = client.persist(dask_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7546115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    today be work quotquirky qquot cue maybe concerto\n",
       "1    shannonelizab not ya know people love human so...\n",
       "2           ughhh reject 09 mediation program suckssss\n",
       "3                 petewentz be jealous want octo drive\n",
       "4    remember hype movie aaliyah kill fan ms rice n...\n",
       "5    like bit friend hate s sex s little nudity epi...\n",
       "6                               love spring definitely\n",
       "7                          jeg007jeg yay   coutchcouch\n",
       "8    work store facebook group get ready relax play...\n",
       "9    falselove oh s good 4 haunted housesound baker...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask_review.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee5414e",
   "metadata": {},
   "source": [
    "#### Performing word-embeddings with TfIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf55274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d47e4c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d42fae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf_vectorizer.fit_transform(dask_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48b37782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "839fd68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90748168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44100, 105281)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1e95e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = twitter_df['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15820184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        1\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "44095    2\n",
       "44096    2\n",
       "44097    2\n",
       "44098    2\n",
       "44099    0\n",
       "Name: Sentiment, Length: 44100, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d5624a",
   "metadata": {},
   "source": [
    "#### Splitting the dataset into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29f8c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd8289cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = tts(X,Y,test_size = 0.30,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c31336",
   "metadata": {},
   "source": [
    "#### Building the different models:\n",
    "1) Logistic Regression -> Base Model<br>\n",
    "2) Random Forest Classifier<br>\n",
    "3) XGBoost Classifier<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cfa45501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "607eec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_classifier = LogisticRegression(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "acb23add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_classifier.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "651e926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = logit_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7b41b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ebbaa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66cf40ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5692,    1,    6],\n",
       "       [1844,    8,    4],\n",
       "       [5664,    6,    5]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f88306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa22e3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60      5699\n",
      "           1       0.53      0.00      0.01      1856\n",
      "           2       0.33      0.00      0.00      5675\n",
      "\n",
      "    accuracy                           0.43     13230\n",
      "   macro avg       0.43      0.33      0.20     13230\n",
      "weighted avg       0.40      0.43      0.26     13230\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2952a712",
   "metadata": {},
   "source": [
    "#### Performing hyperparameter tuning for logistic regression classifier.<br>\n",
    " - Although there aren't any specific hyperparameters, there are few parameters to tune:<br>\n",
    "     (1) Solver<br>\n",
    "     (2) C values\n",
    " - Here, Grid Search CV will be performed to execute the tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c8ecaa",
   "metadata": {},
   "source": [
    "#### Performing repeated k-fold cross-validation on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d97a8d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8de5acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ceabcb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits = 10,random_state = 0, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b15a9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27b321ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values = [100,10,1,0.1,0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "803c03e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = dict(solver = solvers,C = c_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "acd55959",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(estimator = logit_classifier,param_grid = grid_params,scoring='accuracy',cv=cv,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d5054aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "result_grid_cv = grid_cv.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "67f517e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score and optimal hyperparameter values are: (0.4409782960803369, {'C': 100, 'solver': 'lbfgs'})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best score and optimal hyperparameter values are: {result_grid_cv.best_score_,result_grid_cv.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160441fa",
   "metadata": {},
   "source": [
    "#### It can be seen that even with tuning, the model is performing poorly. Proceeding to the bagging and boosting algorithms to build a better model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a6206f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6093230c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602b441f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
